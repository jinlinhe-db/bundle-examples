resources:
  jobs:
    batch_inference_job:
      name: ${bundle.target}-${var.model_name}-inference-job
      tasks:
        - task_key: batch_inference_job
          new_cluster:
            num_workers: 3
            spark_version: 13.3.x-cpu-ml-scala2.12
            node_type_id: r3.xlarge
            custom_tags:
              clusterSource: mlops-stack/0.2
            # aws_attributes:
            #   availability: SPOT_WITH_FALLBACK,
            #   ebs_volume_count: 0,
            #   ebs_volume_size: 0,
            #   first_on_demand: 0,
            #   spot_bid_price_percent: 0,
            #   zone_id: us-east-1a
          notebook_task:
            notebook_path: ../deployment/batch_inference/notebooks/BatchInference.py
            base_parameters:
              env: ${bundle.target}
              input_table_name: ${var.catalog_name}.`${var.schema_name}`.`taxi_scoring_sample`  # TODO: create input table for inference
              output_table_name: ${var.catalog_name}.`${var.schema_name}`.`predictions`
              model_name: ${var.catalog_name}.${var.schema_name}.${var.model_name}
              git_source_info: url:${bundle.git.origin_url}; branch:${bundle.git.branch}; commit:${bundle.git.commit}
      permissions:
      - level: CAN_VIEW
        group_name: users
      - level: CAN_MANAGE
        group_name: SGIA_TEAM_RD_AI_Platform
      # schedule:
      #   quartz_cron_expression: "0 0 11 * * ?" # daily at 11am
      #   pause_status: PAUSED
      #   timezone_id: UTC
      # If you want to turn on notifications for this job, please uncomment the below code,
      # and provide a list of emails to the on_failure argument.
      #
      #  email_notifications:
      #    on_failure:
      #      - first@company.com
      #      - second@company.com
